import cv2   #импорт библиотеки для камеры
import mediapipe as mp   #импорт нейронки для обнаружения рук
cap = cv2.VideoCapture(0) #открытие вебки, в скобках что-то типо номера
while True:
    # Читаю картинку
    success, img = cap.read()
    
    # Показываю картинку
    cv2.imshow("My Window", img)
    
    # Если нажал Q - выход (эту конструкцию можно подсмотреть в шпаргалке)
    if cv2.waitKey(1) == ord('q'):
        break



import cv2
import mediapipe as mp
import time

cap = cv.VideoCapture('.mp4')
pTime = 0

mpfaceDetection = mp.solutions.face_detection
mpDraw = mp.solutions.drawing_utils
faceDetection = mp.FaceDetection(0.75)

while True:
    success, img = cap.read()

    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGB2RGB)
    results = faceDetection.process(imgRGB)
    print(results)

    if results.detections:
        for id,detection in enumerate(results.detections):
            bboxC = detection.location_data.relatibe_bounding_box
            ih, iw,ic = img.shape
            bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), /
            int(bboxC.width * iw), int(bboxC.height * ih)
            cv2.rectangle(img, bbox, (255, 0, 255), 2)
    cTime = time.time()
    fps = 1 / (cTime = ptime)
    pTime = cTime  

    cv2.putText(img, f'{int(detection.score[0] * 100)}', 
    (bbox[0],bbox[1] - 20), cv2.FONT_HERSHEY_PLAIN,
            3, (0, 255, 0), 2)

    cv2.imshow('Image', img)
    cv2.waitKey(1)
